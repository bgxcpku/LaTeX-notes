% -*- TeX -*- -*- UK -*-
% ----------------------------------------------------------------
% arXiv Paper ************************************************
%
% Subhaneil Lahiri's template
%
% Before submitting:
%    Comment out hyperref
%    Comment out showkeys
%    Replace \input{mydefs.tex} with its contents
%       or include mydefs.tex in zip/tar file
%    Replace \input{newsymb.tex} with its contents
%       or include newsymb.tex in zip/tar file
%    Put this file, the .bbl file, any picture or
%       other additional files and natbib.sty
%       file in a zip/tar file
%
% **** -----------------------------------------------------------
\documentclass[12pt]{article}
%
% Preamble:
\input{sl_preamble.tex}
\input{sl_graphics_preamble.tex}
\graphicspath{{figs/}}
%
% >> Only for drafts! <<
\usepackage[notref,notcite]{showkeys}
%
% ----------------------------------------------------------------
%\numberwithin{equation}{section}
%\renewcommand{\baselinestretch}{1.5}
% ----------------------------------------------------------------
% New commands etc.
\input{sl_definitions.tex}
\input{sl_symbols.tex}
%matrices
\newcommand{\inv}{^{-1}}
\newcommand{\dg}{^\dagger}
\newcommand{\trans}{^\mathrm{T}}
\newcommand{\I}{\mathbf{I}}
\newcommand{\omb}{\overline{\omega}}
\newcommand{\dw}{\dr w}
\newcommand{\dwb}{\dr\overline{w}}
\newcommand{\du}{\dr u}
\newcommand{\dub}{\dr\bar{u}}
\newcommand{\dv}{\dr v}
\newcommand{\dvb}{\dr\bar{v}}
% ----------------------------------------------------------------
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title info:
\title{Illusions of criticality in high-dimensional autoregressive models}
%
% Author List:
%
\author{Subhaneil Lahiri and Surya Ganguli
%
}

\begin{document}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{abstract}
  We look at the eigenvalue spectrum of high-dimensional autoregressive models when applied to white-noise.
\end{abstract}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of Article:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The problem}\label{sec:theprob}

Consider a model of the following type
%
\begin{equation}\label{eq:model}
  x(t+1) = A x(t) + \text{noise},
\end{equation}
%
where $x(t)$ is an $N$-element vector and $A$ is an $N\times N$ matrix.

Suppose we have a sample of $P$ consecutive times, so $x$ is an $N\times P$ matrix.
We can perform a least-squares estimate of $A$ by minimising the quantity
%
\begin{equation}\label{eq:minL}
  \half\sum_{i,\mu} \prn{ x_{i\mu+1} - \sum_j A_{ij} x_{j\mu} }^2 = \half\Tr \prn{xU-Ax}\prn{xU-Ax}\trans,
\end{equation}
%
where $U$ is a shift matrix.
It will be useful to use periodic boundary conditions in time, \ie $x_{iP+1}\sim x_{i1}$,
as this will make $U$ orthogonal:
%
\begin{equation}\label{eq:Udef}
  U_{\mu\nu} = \delta_{\mu\nu+1} + \delta_{\mu1}\delta_{\nu P}.
\end{equation}
%
The estimate of $A$ is then
%
\begin{equation}\label{eq:Aest}
  A = \prn{xUx\trans}\prn{xx\trans}\inv.
\end{equation}
%

Suppose we attempted this analysis in a situation where there really is no structure,
\ie when $x(t)$ is white noise.
Then the true optimal $A$ would be 0.
However, with finite $P$ the estimate \eqref{eq:Aest} will not be zero.

We will look at the average eigenvalue distribution:
%
\begin{equation}\label{eq:eigdist}
  \rho(\omega) = \av{\rho_A(\omega)}_x,
  \qquad
  \rho_A = \sum_{i=1}^N \delta(\omega-\lambda_i),
\end{equation}
%
where $\lambda_i$ are the eigenvalues of $A$ in \eqref{eq:Aest} and
the components of $x$ are iid gaussian random variables with mean 0 and variance 1.
This quantity is most relevant in the limit of large $N$ and $P$.
We will keep the quantity $\alpha=P/N$ fixed in this limit.

Following \cite{Sommers1988asymmetric}, this can be computed from a potential:
%
\begin{equation}\label{eq:potential}
  \rho_A(\omega) = -\nabla^2 \Phi_A(\omega),
  \qquad
  \Phi_A(\omega) = -\frac{1}{4\pi N} \ln\det \brk{(\omb-A\trans)(\omega-A)}.
\end{equation}
%
We define a partition function
%
\begin{equation}\label{eq:partfn}
  \Phi_A(\omega) = \frac{1}{4\pi N} \ln Z_A(\omega),
  \qquad
  Z_A(\omega) = \det \brk{(\omb-A\trans)(\omega-A)}\inv.
\end{equation}
%
The problem is now to compute $\av{\ln Z_A(\omega)}_x$.



\section{Simplified derivation}\label{sec:simplederiv}

In this section, we will present a simplified version of the derivation.
We will make the following simplifying assumption.

At some point, we will treat $x$ as annealed, rather than quenched, disorder:
%
\begin{equation}\label{eq:annealed}
  \av{\ln (\cdots)}_x = \ln\av{\cdots}_x.
\end{equation}
%
We will justify this assumption in \sref{sec:replicader} using the replica trick.
We will see that, with a replica symmetric ansatz, the saddle point has zero off-diagonal replica overlaps.
This means that there is no coupling between the replicas, which produces identical results to the annealed calculation.

We start with the representation of the determinant in \eqref{eq:compgausint}.
However, the matrix in \eqref{eq:partfn} is not positive-definite when $\omb$ is equal to one of the eigenvalues.
We can fix this by adding $\epsilon^2I$ and letting $\epsilon\to0$ at the end.
%
\begin{equation}\label{eq:partfnintz}
\begin{aligned}
  Z_A(\omega) &= \int \prod_i\frac{\dz_i\dzb_i}{2\pi} \exp\prn{
    -z\dg (\omb-A\trans)(\omega-A) z - \epsilon^2 z\dg z} .%\\
%    &=  \int \prod_i\frac{\dz_i\dzb_i}{2\pi} \exp\prn{
%    -z\dg (xx\trans)\inv x(\omb-U)x\trans x(\omega-U)x\trans (xx\trans)\inv z
%    - \epsilon^2 z\dg z}. \\
\end{aligned}
\end{equation}
%
Looking at the expression \eqref{eq:Aest} for $A$, we make the change of variables $z=(xx\trans)w/P$.
%
\begin{equation}\label{eq:partfnintw}
\begin{aligned}
  Z_A(\omega) &= \det(xx\trans)^2 \int \prod_i\frac{\dw_i\dwb_i}{2\pi}\e^{-F/P^2}
    \\
  F &=
     w\dg x(\omb-U\trans)x\trans x(\omega-U)x\trans w + \epsilon^2 w\dg xx\trans xx\trans w .%\\
\end{aligned}
\end{equation}
%
We now take advantage of \eqref{eq:compgausslin} by introducing two standard complex Gaussian random vectors ($C=I$ in \eqref{eq:compgaussnorm}), $u$ and $v$:
%
\begin{equation}\label{eq:partfnintwuv}
\begin{aligned}
  Z_A(\omega) &= \det(xx\trans)^2 \int \prod_i\frac{\dw_i\dwb_i}{2\pi} \av{\e^{\ir F'/P}}_{u,v},\\
  F' &=
    w\dg x(\omb-U\trans)x\trans u + u\dg x(\omega-U)x\trans w + \epsilon w\dg xx\trans v + \epsilon v\dg xx\trans w .%\\
\end{aligned}
\end{equation}
%

Over most of the integration domain, we expect the real inner products ($w\dg w, u\dg u,\ldots$) will be $\CO(N)$, whereas the complex inner products ($w\dg u, w\trans w,\ldots$) will be $\CO(\sqrt{N})$.
We define some new variables, $\rho,\sigma \text{ and } \tau$, which are zero mean Gaussian random vectors:
%
\begin{equation}\label{eq:rstdef}
\begin{aligned}
  \rho &= x\trans w ,
    & \av{\bar{\rho}_\mu \rho_\nu}_x &= Nr\delta_{\mu\nu} ,
    & r&=\frac{w\dg w}{N}, \\
  \sigma &= x\trans u ,
    & \av{\bar{\sigma}_\mu \sigma_\nu}_x &= Ns\delta_{\mu\nu} ,
    & s&=\frac{u\dg u}{N}, \\
  \tau &= x\trans v,
    & \av{\bar{\tau}_\mu \tau_\nu}_x &= Nt\delta_{\mu\nu},
    & t&=\frac{v\dg v}{N}, \\
\end{aligned}
\end{equation}
%
with all other covariances negligible in the large $N$ limit.
We can now write
%
\begin{equation}\label{eq:potwuv}
\begin{aligned}
  \av{\ln Z_A(\omega)}_x =&\,  2\av{\ln\det(xx\trans)}_x 
  \\&+ 
          \av{\ln\int \prod_i\brk{ \frac{\dw_i\dwb_i}{2\pi} \frac{\du_i\dub_i}{2\pi} \frac{\dv_i\dvb_i}{2\pi} } \e^{-N(s+t)-\xi\dg A \xi} }_{\xi} ,
  \\ \text{where}\quad
  \xi =&\, \begin{pmatrix}
           \rho \\
           \sigma \\
           \tau \\
         \end{pmatrix},
 \\
  A =&\, -\frac{\ir}{P}
       \begin{pmatrix}
         0        & \omb-U\trans & \epsilon \\
         \omega-U & 0            & 0 \\
         \epsilon & 0            & 0 \\
       \end{pmatrix}.
\end{aligned}
\end{equation}
%
As we only care about the part of $\Phi$ that depends on $\omega$, we can ignore the first term.
We will simplify the second term using \eqref{eq:annealed} and the relation
%
\begin{equation}\label{eq:spherical}
  \int \prod_i\brk{ \frac{\dw_i\dwb_i}{2\pi} } f(r) = \frac{N^N}{\Gamma(N)} \intd{r} r^{N-1} f(r),
\end{equation}
%
along with similar ones for $u$ and $v$, to get
%
\begin{equation}\label{eq:phiintsimple}
\begin{aligned}
  \Phi &= \text{const.} + \frac{1}{4\pi N} \ln \int \frac{\dr r}{r} \frac{\dr s}{s} \frac{\dr t}{t}
      (rst)^N\e^{-N(s+t)} \av{\e^{-\xi\dg A \xi}}_\xi\\
      &= \text{const.} + \frac{1}{4\pi N} \ln \int \frac{\dr r}{r} \frac{\dr s}{s} \frac{\dr t}{t}
      \,\frac{\exp[N(\ln(rst)-s-t)]}{\det(I+CA)},\\
  \text{where}\quad
  C &= N\begin{pmatrix}
         r & 0 & 0 \\
         0 & s & 0 \\
         0 & 0 & t \\
       \end{pmatrix}.
\end{aligned}
\end{equation}
%

As $U$ is unitary, all the blocks in these matrices commute.
Therefore, we can evaluate the determinant with some help from \cite{silvester2000determinants}.
Also noting that the eigenvalues of $U$ are $\exp(2\pi\ir k/P)$, with $k\in\Z_P$:
%
\begin{equation}\label{eq:detsimple}
\begin{aligned}
  \ln\det(I+CA) &= \ln\det\brk{\frac{1}{\alpha^3}
       \begin{pmatrix}
         \alpha           & -\ir r(\omb-U\trans) & -\ir\epsilon r \\
         -\ir s(\omega-U) & \alpha               & 0 \\
         -\ir\epsilon t   & 0                    & \alpha \\
       \end{pmatrix}}\\
     &= \ln\det\brk{\frac{\alpha^2+\epsilon^2rt + rs(\omb-U\trans)(\omega-U)}{\alpha^2}}\\
     &= \sum_{k=0}^{P-1} \ln\brk{ \frac{\alpha^2+\epsilon^2rt + rs (\omb-\e^{-2\pi\ir k/P}) (\omega-\e^{2\pi\ir k/P})} {\alpha^2}}\\
     &= \frac{P}{2\pi} \intd[_0^{2\pi}]{\phi} \ln\brk{ \frac{\alpha^2+\epsilon^2rt + rs (\omb-\e^{-\ir\phi}) (\omega-\e^{\ir\phi})} {\alpha^2}}\\
     &= \frac{P}{2\pi\ir} \int \frac{\dr\zeta}{\zeta} \, \ln \brk{\frac{G(\zeta)}{\alpha^2\zeta}},
\end{aligned}
\end{equation}
%
$(C\inv+A)$ IS NON-NORMAL!
where the function $G(\zeta)$ is defined in \sref{sec:Gamma}, in particular \eqref{eq:Gammadef}.
The denominator of the logarithm contributes a factor that is independent of $\omega$, which can be safely ignored.

If we factor $G(\zeta)$, we get some contour integrals of the form discussed in \sref{sec:contourints}, the result of which appears in \eqref{eq:countourintresult}.
From \eqref{eq:zpzm}, we know that only one of the zeros of $G(\zeta)$ will ie inside the contour.
We find that
%
\begin{equation}\label{eq:detsimpleresult}
\begin{aligned}
  \ln\det(I+CA) &= \text{const.} + P[\ln(-rs\omb) + \ln\zeta_+ + \ln\zeta_- - \ln(\min\abs{\zeta_\pm})]   \\
   &= \text{const.} + P\ln\prn{-\frac{rs\omega}{\min\abs{\zeta_\pm}}}.
\end{aligned}
\end{equation}
%

Now, if we use the saddle-point approximation of the integrals over $r$, $s$ and $t$ in \eqref{eq:phiintsimple}, which becomes exact in the limit of large $N$ and $P$, we find
%
\begin{equation}\label{eq:phisaddlesimple}
  \Phi = \frac{1}{4\pi} \max_{r,s,t} \brk{ \ln(rst) - s - t -\alpha\ln\prn{-\frac{rs\omega}{\min\abs{\zeta_\pm}}}}.
\end{equation}
%
One can show that (see \sref{sec:replicader}) the maximum occurs with
%
\begin{equation}\label{eq:saddleOe}
  r \sim \CO(\epsilon\inv),
  \qquad
  s \sim \CO(\epsilon),
  \qquad
  t \sim \CO(1),
  \qquad
  rs \sim \CO(1).
\end{equation}
%
If we take $\epsilon\to0$, we find that $\Phi$ depends on $r$, $s$ and $t$ in the combinations $rs$ and $t$:
%
\begin{equation}\label{eq:phimaxsimple}
\begin{aligned}
  \Phi &= \frac{1}{4\pi} \max_{rs,t} \brk{ (1-\alpha)\ln(rs)+\ln t - t -\alpha\ln\prn{-\frac{\omega}{\min\abs{\zeta_\pm}}}}\\
  \pdiff{\Phi}{(rs)} &= \frac{1-\alpha}{rs} + \alpha\Re\prn{\frac{\alpha^2}{rs G'(\min\abs{\zeta_\pm})}} ,\\
  \pdiff{\Phi}{t}&= \frac{1}{t} - 1 .
\end{aligned}
\end{equation}
%
These equations require
%
\begin{equation}\label{eq:saddlereq}
  \abs{\zeta_-}<1,
  \qquad
  [\alpha^2+rs(1+\abs{\omega}^2)]^2 > 4(rs)^2\abs{\omega}^2,
\end{equation}
%
in which case
%
\begin{equation}\label{eq:saddlesol}
\begin{aligned}
  t &=1, \\
  rs &= \frac{\alpha^2 \brk{ -(\alpha-1)(1+\abs{\omega}^2) \pm \sqrt{ (\alpha-1)^2(1+\abs{\omega}^2)^2 - (2\alpha-1)(1-\abs{\omega}^2)^2 } }}{(\alpha-1)(1-\abs{\omega}^2)^2},\\
  \zeta_- &= \frac{1+\abs{\omega}^2}{2\omb} - \frac{\alpha^2}{2(\alpha-1)\omb rs},\\
 \Phi &= \frac{1}{4\pi}\brk{ (1-\alpha)\ln(rs) -\alpha\ln\prn{-\frac{\omega}{\abs{\zeta_-}}}}
\end{aligned}
\end{equation}
%






\section{Full, replica-tastic derivation}\label{sec:replicader}



%\subsection*{Acknowledgements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Appendices}
\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Complex Gaussian integrals}\label{sec:compgauss}

First, Let's get all of the factors of 2 straight.
Note that if we write $z=x+\ir y$, then $\dz\dzb = 2\dx\dy$.
Let $H$ be a positive-definite, $N\times N$ Hermitian matrix.
Consider an integral  of the form
%
\begin{equation*}
  \int \prn{\prod_i\dz_i\dzb_i} \exp\prn{-z\dg H z}.
\end{equation*}
%
We can diagonalise $H$ with a unitary change of variables:
%
\begin{equation}\label{eq:compgausint}
\begin{aligned}
  \int \prn{\prod_i\dz_i\dzb_i} \exp\prn{-z\dg H z} &=
    \prod_i \int \dz_i\dzb_i\, \exp\prn{-\lambda_i \abs{z_i}^2} \\
    &= \prod_i \int \dx_i\dy_i\, 2\exp\prn{-\lambda_i \prn{x_i^2+y_i^2}} \\
    &= \prod_i \frac{2\pi}{\lambda_i}\\
    &= \frac{(2\pi)^N}{\det H}.
\end{aligned}
\end{equation}
%

The proper normalisation for a Gaussian distribution is
%
\begin{equation}\label{eq:compgaussnorm}
  P(z,z\dg)\dz\dz\dg = \prn{\prod_i\frac{\dz_i\dzb_i}{2\pi}} \frac{\exp\prn{-z\dg C\inv z}}{\det C}.
\end{equation}
%
By completing the square, we can see that
%
\begin{equation}\label{eq:compgausslin}
  \av{\exp\prn{\zeta\dg z + z\dg\zeta}} = \exp\prn{\zeta\dg C\zeta}.
\end{equation}
%
Taking partial derivatives \wrt $\zeta_i$ and $\bar{\zeta}_i$, we find
%
\begin{equation}\label{eq:compgauscov}
  \av{zz\dg} = C.
\end{equation}
%

Now consider an integral of the form
%
\begin{equation}\label{eq:compgaussquad}
\begin{aligned}
  \av{\exp\prn{-z\dg A z}} &=
    \int \prn{\prod_i\frac{\dz_i\dzb_i}{2\pi}}\frac{\exp\prn{-z\dg (C\inv+A) z}}{\det C} \\
    &= \prn{\det C\det\prn{C\inv+A}}\inv \\
    &= \det\prn{I+CA}\inv.
\end{aligned}
\end{equation}
%
ONLY WORKS IF $(C\inv+A)$ IS POS DEF, OR AT LEAST NORMAL!


\section{Contour integrals for determinants}\label{sec:contourints}

In evaluating determinants, we will come across contour integrals of the form
%
\begin{equation}\label{eq:contourint}
  I(z) = \frac{1}{2\pi\ir}\int \frac{\dr\zeta}{\zeta} \ln(z-\zeta),
\end{equation}
%
where the contour is the unit circle in a counter-clockwise direction.
The contour might not be closed because of the branch cut.
We choose the branch of the logarithm so that
%
\begin{equation}\label{eq:branch}
  \arg\prn{\frac{\zeta-z}{z}} \in [0,2\pi],
\end{equation}
%
and we define $\theta=\arg z$. The branch cut is shown in \fref{fig:contours}.

\begin{figure}
 \begin{center}
 \begin{myenuma}
  \item\aligntop{\includegraphics[width=5cm]{contout.svg}}\label{fig:contout}
  \hspace{1cm}
  \item\aligntop{\includegraphics[width=5cm]{contin.svg}}\label{fig:contin}
 \end{myenuma}
 \end{center}
  \caption{Contours used to evaluate \eqref{eq:contourint}, (\ref{fig:contout}) when $\abs{z}>1$, (\ref{fig:contin}) when $\abs{z}<1$.}\label{fig:contours}
\end{figure}

If $\abs{z}>1$, we can use the contour $C_1$ in \fref{fig:contours}(\ref{fig:contout}).
Using the residue theorem:
%
\begin{equation}\label{eq:intout}
  I(z) = \frac{1}{2\pi\ir}\int_{C_1} \frac{\dr\zeta}{\zeta} \ln(z-\zeta) = \ln z.
\end{equation}
%

If $\abs{z}>1$, we can use the contour $C_2$ in \fref{fig:contours}(\ref{fig:contin}):
%
\begin{equation}\label{eq:contout}
C_2: \quad
  \begin{aligned}
    \zeta &= \e^{\ir\phi},                             & \phi &\in [\theta+\delta,\theta+2\pi-\delta], \\
    \zeta &= \e^{\ir(\theta+2\pi-\delta)}+xz\prn{1-\e^{\ir(2\pi-\delta)}},
                                                       & x    &\in [0,1], \\
    \zeta &= z - x \e^{\ir(\theta+2\pi-\delta)}, \quad & x    &\in [\abs{z}-1,-\epsilon], \\
    \zeta &= z + \epsilon\e^{-\ir\phi},                & \phi &\in [-\theta-2\pi+\delta,-\theta-\delta], \\
    \zeta &= z + x \e^{\ir(\theta+\delta)},          & x    &\in [\epsilon,1-\abs{z}.] \\
    \zeta &= \e^{\ir(\theta+\delta)}+(1-x)z\prn{1-\e^{\ir\delta}},
                                                       & x    &\in [0,1], \\
  \end{aligned}
\end{equation}
%
Using the residue theorem:
%
\begin{equation}\label{eq:intin}
  \frac{1}{2\pi\ir}\int_{C_2} \frac{\dr\zeta}{\zeta} \ln(z-\zeta) = \ln z.
\end{equation}
%
If we let $\delta,\epsilon\to0$, the second, fourth and sixth parts of the contour integral vanish, and the first part gives $I(z)$ in \eqref{eq:contourint}.
We're left with
%
\begin{equation}\label{eq:intinlim}
  \begin{aligned}
    \ln z =&\, I(z)
           -\frac{1}{2\pi\ir} \int_{\abs{z}-1}^{0} \frac{\e^{\ir\theta}\dx}{z-x\e^{\ir\theta}} \ln\prn{x\e^{\ir(\theta+2\pi)}} %\\&
           +\frac{1}{2\pi\ir} \int_{0}^{1-\abs{z}} \frac{\e^{\ir\theta}\dx}{z+x\e^{\ir\theta}} \ln\prn{-x\e^{\ir\theta}}  \\
      =&\, I(z)
           -\frac{1}{2\pi\ir} \int_{0}^{1-\abs{z}} \frac{\dx}{\abs{z}+x} \ln\prn{-x\e^{\ir(\theta+2\pi)}} %\\&
           +\frac{1}{2\pi\ir} \int_{0}^{1-\abs{z}} \frac{\dx}{\abs{z}+x} \ln\prn{-x\e^{\ir\theta}}  \\
      =&\, I(z) - \int_{0}^{1-\abs{z}} \frac{\dx}{\abs{z}+x}  \\
      =&\, I(z) + \ln\abs{z}.
  \end{aligned}
\end{equation}
%

Therefore:
%
\begin{equation}\label{eq:countourintresult}
  I(z) = \frac{1}{2\pi\ir}\int \frac{\dr\zeta}{\zeta} \ln(z-\zeta)
   = \ln z - [\ln\abs{z}]_-
   = \ir \arg z + [\ln\abs{z}]_+,
\end{equation}
%
where $[x]_\pm = x \theta(\pm x)$ and $\theta(x)$ is the Heaviside step function.


\section{The quadratic function \texorpdfstring{$G(\zeta)$}{G(zeta)}}\label{sec:Gamma}

In evaluating determinants in \sref{sec:simplederiv} and \sref{sec:replicader}, we come across the function
%
\begin{equation}\label{eq:Gammadef}
  G(\zeta) = (\alpha^2+\epsilon^2rt)\zeta + rs(\omb\zeta-1)(\omega-\zeta) = - rs\omb (\zeta-\zeta_+) (\zeta-\zeta_-).
\end{equation}
%
We will collect some useful features of $\zeta_\pm$ here.

First, by comparing the two forms of $G(\zeta)$, we see that:
%
\begin{align}
\label{eq:zpzm}
  \zeta_+ \zeta_- &= \frac{\omega}{\omb},\\
  \label{eq:zppzm}
  \zeta_+ + \zeta_- &= \frac{\alpha^2+\epsilon^2rt + rs(1+\abs{\omega}^2)}{rs\omb},\\
  \label{eq:Gprime}
  G'(\zeta_\pm) = \mp rs\omb(\zeta_+ - \zeta_-),
\end{align}
%
and \eqref{eq:zpzm} tells us that $\abs{\zeta_+} \abs{\zeta_-}=1$.
Solving the equation $G(\zeta_\pm)=0$ gives
%
\begin{align}
%\label{eq:zetapm}
%  \zeta_\pm &= \frac{ \alpha^2+\epsilon^2rt + rs(1+\abs{\omega})^2
%     \pm \sqrt{\brk{\alpha^2+\epsilon^2rt + rs(1+\abs{\omega})^2}
%       - 4(rs)^2\abs{\omega}^2} }{2rs\omb},\\
%\label{eq:zpmzm}
%  \zeta_+ - \zeta_- &= \frac{\sqrt{\brk{\alpha^2+\epsilon^2rt + rs(1+\abs{\omega}^2)}
%       - 4(rs)^2\abs{\omega}^2} }{rs\omb},\\
\label{eq:Gprimesol}
  G'(\zeta_\pm) &= \mp\sqrt{\brk{\alpha^2+\epsilon^2rt + rs(1+\abs{\omega}^2)}
       - 4(rs)^2\abs{\omega}^2}.
\end{align}
%
Differentiating the equation $G(\zeta_\pm)=0$ gives
%
\begin{align}
\label{eq:dzpmdr}
  \pdiff{\zeta_\pm}{r} &=
    -\frac{\epsilon^2t\zeta_\pm + s(\omb\zeta_\pm-1)(\omega-\zeta_\pm)}{G'(\zeta_\pm)}
    &&= \frac{\alpha^2\zeta_\pm}{rG'(\zeta_\pm)},\\
\label{eq:dzpmds}
  \pdiff{\zeta_\pm}{s} &=
    -\frac{r(\omb\zeta_\pm-1)(\omega-\zeta_\pm)}{G'(\zeta_\pm)}
    &&= \frac{(\alpha^2+\epsilon^2rt)\zeta_\pm}{sG'(\zeta_\pm)},\\
\label{eq:dzpmdt}
  \pdiff{\zeta_\pm}{r} &=
    -\frac{\epsilon^2r\zeta_\pm}{G'(\zeta_\pm)}.
\end{align}
%

It will also be helpful to note that
%
\begin{equation}\label{eqdabsz}
  \frac{\dr\abs{\zeta_\pm}}{\abs{\zeta_\pm}} = \Re\prn{\frac{\dr\zeta_\pm}{\zeta_\pm}}.
\end{equation}
%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{utcaps_sl}
\bibliography{maths,qft,neuro}

\end{document}
