% -*- TeX -*- -*- UK -*-
% ----------------------------------------------------------------
% arXiv Paper ************************************************
%
% Subhaneil Lahiri's template
%
% Before submitting:
%    Comment out hyperref
%    Comment out showkeys
%    Replace \input{mydefs.tex} with its contents
%       or include mydefs.tex in zip/tar file
%    Replace \input{newsymb.tex} with its contents
%       or include newsymb.tex in zip/tar file
%    Put this file, the .bbl file, any picture or
%       other additional files and natbib.sty
%       file in a zip/tar file
%
% **** -----------------------------------------------------------
\documentclass[12pt]{article}
%
% Preamble:
\usepackage{a4wide}
\input{sl_preamble.tex}
\input{sl_graphics_preamble.tex}
\graphicspath{{figs/}}
%
% >> Only for drafts! <<
\usepackage[notref,notcite]{showkeys}
%
% ----------------------------------------------------------------
%\numberwithin{equation}{section}
%\renewcommand{\baselinestretch}{1.5}
% ----------------------------------------------------------------
% New commands etc.
\input{sl_definitions.tex}
\input{sl_symbols.tex}
%matrices
\newcommand{\inv}{^{-1}}
\newcommand{\dg}{^\dagger}
\newcommand{\trans}{^\mathrm{T}}
\newcommand{\I}{\mathbf{I}}
\newcommand{\shift}{\mathcal{S}}
\newcommand{\aest}{\hat{A}}
\newcommand{\omb}{\overline{\omega}}
\newcommand{\bt}{\overline{\tau}}
\newcommand{\dw}{\dr w}
\newcommand{\dwb}{\dr\overline{w}}
\newcommand{\du}{\dr u}
\newcommand{\dub}{\dr\bar{u}}
\newcommand{\dv}{\dr v}
\newcommand{\dvb}{\dr\bar{v}}
\newcommand{\oa}{\abs{\omega}}
\newcommand{\oas}{\abs{\omega}^2}
\newcommand{\opo}{\prn{1+\abs{\omega}^2}}
\newcommand{\omo}{\prn{1-\abs{\omega}^2}}
\newcommand{\omoa}{\abs{1-\abs{\omega}^2}}
% ----------------------------------------------------------------
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title info:
\title{Illusions of criticality in high-dimensional autoregressive models}
%
% Author List:
%
\author{Subhaneil Lahiri and Surya Ganguli
%
}

\begin{document}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{abstract}
  We look at the eigenvalue spectrum of high-dimensional autoregressive models when applied to white-noise.
\end{abstract}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of Article:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The problem}\label{sec:theprob}

Consider a model of the following type
%
\begin{equation}\label{eq:model}
  x(t+1) = A x(t) + \text{noise},
\end{equation}
%
where $x(t)$ is an $N$-element vector and $A$ is an $N\times N$ matrix.

Suppose we have a sample of $P$ consecutive times, so $x$ is an $N\times P$ matrix.
We can perform a least-squares estimate of $A$ by minimising the quantity
%
\begin{equation}\label{eq:minL}
  \half\sum_{i,\mu} \prn{ x_{i\mu+1} - \sum_j \aest_{ij} x_{j\mu} }^2 = \half\Tr \prn{x\shift-\aest x}\prn{x\shift-\aest x}\trans,
\end{equation}
%
where $\shift$ is a shift matrix.
It will be useful to use periodic boundary conditions in time, \ie $x_{iP+1}\sim x_{i1}$,
as this will make $\shift$ orthogonal:
%
\begin{equation}\label{eq:Udef}
  \shift_{\mu\nu} = \delta_{\mu\nu+1} + \delta_{\mu1}\delta_{\nu P}.
\end{equation}
%
The estimate of $A$ is then
%
\begin{equation}\label{eq:Aest}
  \aest = \prn{x\shift x\trans}\prn{xx\trans}\inv = x\shift x^*,
\end{equation}
%
where $x^*$ is the pseudoinverse of $x$, \ie $xx^*=I$.

Suppose we attempted this analysis in a situation where there really is no structure,
\ie when $A=0$ and $x(t)$ is just white noise.
For large enough $P$, we should get $\aest=0$.
However, with finite $P$ the estimate \eqref{eq:Aest} will not be zero.

Moreover if $P=N$, generically $x$ will be invertible, so $x^*=x\inv$.
This would mean that \eqref{eq:Aest} is a similarity transform of $\shift$, and will therefore have the same eigenvalues: $\exp(2\pi\ir k/P)$ for $k\in\Z_P$.
We would be fooled into thinking the system was critical (eigenvalues of absolute value 1) when in reality there is only noise.
This raises the question, how large must $\alpha=P/N$ be to avoid this problem?

We will look at the average eigenvalue distribution:
%
\begin{equation}\label{eq:eigdist}
  \rho(\omega,\omb) = \av{\rho_{\aest} (\omega,\omb)}_x,
  \qquad
  \rho_{\aest}(\omega,\omb) = \sum_{i=1}^N \delta^{(2)}(\omega-\lambda_i),
\end{equation}
%
where $\lambda_i$ are the eigenvalues of $\aest$ in \eqref{eq:Aest} and
the components of $x$ are iid gaussian random variables with mean 0 and variance 1.
This quantity is most relevant in the limit of large $N$ and $P$.
We will keep $\alpha$ fixed in this limit.

Following \cite{Sommers1988asymmetric}, this can be computed from a potential:
%
\begin{equation}\label{eq:potential}
  \rho_{\aest}(\omega,\omb) = -\nabla^2 \Phi_{\aest} (\omega,\omb),
  \qquad
  \Phi_{\aest} (\omega,\omb) = -\frac{1}{4\pi N} \ln\det \brk{(\omb-\aest \trans)(\omega-\aest )}.
\end{equation}
%
We define a partition function
%
\begin{equation}\label{eq:partfn}
  \Phi_{\aest} (\omega,\omb) = \frac{1}{4\pi N} \ln Z_{\aest} (\omega,\omb),
  \qquad
  Z_{\aest} (\omega,\omb) = \det \brk{(\omb-\aest \trans)(\omega-\aest )}\inv.
\end{equation}
%
The problem is now to compute $\av{\ln Z_{\aest} (\omega,\omb)}_x$.


\section{The solution}\label{sec:solution}

In \autoref{sec:simplederiv} we will present a simplified derivation and in \autoref{sec:replicader} we will fill in the gaps and justify the assumptions used in \autoref{sec:simplederiv}.
The result from \eqref{eq:saddlesol}, with some constant pieces dropped, will be:
%
\begin{equation}\label{eq:phisol}
\begin{aligned}
  q &= \frac{ \sqrt{\alpha^2\opo^2 - 4(2\alpha-1)\oas} - (\alpha-1)\opo }{\omo^2},\\
  \Phi(\omega,\omb) &= \frac{1}{4\pi}\brk{ (1-\alpha)\ln q +\alpha\ln\prn{\frac{1+\abs{\omega}^2-q\inv}{2\oas}} },
\end{aligned}
\end{equation}

The potential has a rotation symmetry.
Therefore, we can express the eigenvalue density in terms of the radial density
%
\begin{equation}\label{eq:radialrho}
  \rho(\oa) = \int \rho(\omega,\omb)\oa\dr\phi = 2\pi\oa\rho(\omega,\omb)
   = -\pdiff{}{\oa}\prn{\oa\pdiff{(2\pi\Phi)}{\oa}}.
\end{equation}
%
We find
%
\begin{equation}\label{eq:radialrhosol}
\rho(\oa) =
  \frac{2 (\alpha-1) \oa q}{\sqrt{\alpha^2\opo^2 - 4(2\alpha-1)\oas}}.
\end{equation}
%


Let's look at two interesting limits.

First, $\alpha\to1$:
%
\begin{equation}\label{eq:rszmphiato1}
\begin{aligned}
  q &\to \frac{1}{\omoa},\\
  \implies1+\abs{\omega}^2-q\inv &\to \opo-\omoa =
     \begin{cases}
       2\oas &\text{for } \abs{\omega}<1,\\
       2 &\text{for } \abs{\omega}>1.\\
     \end{cases}\\
  \implies\Phi &\to
     \begin{cases}
       0 &\text{for } \abs{\omega}<1,\\
       -\frac{\ln\abs{\omega}}{2\pi} &\text{for } \abs{\omega}>1.\\
     \end{cases}
\end{aligned}
\end{equation}
%
This is harmonic everywhere except $\abs{\omega}=1$.
Applying Gauss' law to a circular loop of radius greater than 1, centred at the origin, tells us that the total charge enclosed is 1.
Therefore:
%
\begin{equation}\label{eq:rhoato1}
  \rho(\oa) \to \delta(\abs{\omega}-1)
  \quad\text{as}\quad \alpha\to1.
\end{equation}
%


Now, $\alpha\to\infty$:
%
\begin{equation}\label{eq:rsatoinfty}
  q =
  \frac{1}{1+\abs{\omega}^2} \brk{1 + \frac{2\abs{\omega}^ 2}{\alpha\opo^2}
       + \frac{8\abs{\omega}^4}{\alpha^2\opo^4}
       + \CO(\alpha^{-3})},
\end{equation}
%
which leads to
%
\begin{equation}\label{eq:zmatoinfty}
  1+\abs{\omega}^2-q\inv =
  \frac{2\oas}{\alpha\opo} \brk{1 + \frac{2\abs{\omega}^2}{\alpha\opo^2} + \CO(\alpha^{-2})}.
\end{equation}
%
Dropping constants:
%
\begin{equation}\label{eq:phiatoinfty}
  \Phi = -\frac{\ln\opo}{4\pi} + \CO(\alpha^{-1}).
\end{equation}
%
This results in
%
\begin{equation}\label{eq:rhoatoinfty}
  \rho(\oa) \to \frac{2\oa}{\opo^2}
  \quad\text{as}\quad
  \alpha\to\infty.
\end{equation}
%
This should be $\delta(\oa)$.



\section{Simplified derivation}\label{sec:simplederiv}

In this section, we will present a simplified version of the derivation.
We will make the following simplifying assumption: at some point, we will treat $x$ as annealed, rather than quenched, disorder:
%
\begin{equation}\label{eq:annealed}
  \av{\ln (\cdots)}_x = \ln\av{\cdots}_x.
\end{equation}
%
We will justify this assumption in \autoref{sec:replicader} using the replica trick.
We will see that, with a replica symmetric ansatz, the saddle point has zero off-diagonal replica overlaps.
This means that there is no coupling between the replicas so it gives identical results to the annealed calculation.

We start with the representation of the determinant in \eqref{eq:compgausint}.
However, the matrix in \eqref{eq:partfn} is not positive-definite when $\omega$ is equal to one of the eigenvalues.
We can fix this by adding $\epsilon^2I$ and letting $\epsilon\to0$ at the end.
%
\begin{equation}\label{eq:partfnintz}
\begin{aligned}
  Z_{\aest} (\omega,\omb) &= \int \prod_i\frac{\dz_i\dzb_i}{2\pi} \exp\prn{
    -z\dg (\omb-\aest \trans)(\omega-\aest ) z - \epsilon^2 z\dg z} .%\\
%    &=  \int \prod_i\frac{\dz_i\dzb_i}{2\pi} \exp\prn{
%    -z\dg (xx\trans)\inv x(\omb-\shift)x\trans x(\omega-\shift)x\trans (xx\trans)\inv z
%    - \epsilon^2 z\dg z}. \\
\end{aligned}
\end{equation}
%
Looking at the expression \eqref{eq:Aest} for $\aest $, we make the change of variables $z=(xx\trans)w/P$.
%
\begin{equation}\label{eq:partfnintw}
\begin{aligned}
  Z_{\aest} (\omega,\omb) &= \det\prn{\frac{xx\trans}{P}}^2 \int \prod_i\frac{\dw_i\dwb_i}{2\pi}\e^{-F/P^2}
    \\
  F &=
     w\dg x(\omb-\shift\dg)x\trans x(\omega-\shift)x\trans w + \epsilon^2 w\dg xx\trans xx\trans w .%\\
\end{aligned}
\end{equation}
%
We now take advantage of \eqref{eq:compgausslin} by introducing two standard complex Gaussian random vectors ($C=I$ in \eqref{eq:compgaussnorm}), $u$ and $v$:
%
\begin{equation}\label{eq:partfnintwuv}
\begin{aligned}
  Z_{\aest} (\omega,\omb) &= \det\prn{\frac{xx\trans}{P}}^2 \int \prod_i\frac{\dw_i\dwb_i}{2\pi} \av{\e^{\ir F'/P}}_{u,v},\\
  F' &=
    w\dg x(\omb-\shift\dg)x\trans u + u\dg x(\omega-\shift)x\trans w + \epsilon w\dg xx\trans v + \epsilon v\dg xx\trans w .%\\
\end{aligned}
\end{equation}
%

Over most of the integration domain, we expect the real inner products ($w\dg w$,$u\dg u$,\ldots) will be $\CO(N)$, whereas the complex inner products ($w\dg u$,$w\trans w$,\ldots) will be $\CO(\sqrt{N})$.
We define some new variables, $\rho,\sigma \text{ and } \tau$, which are zero mean Gaussian random vectors:
%
\begin{equation}\label{eq:rstdef}
\begin{aligned}
  \rho &= x\trans w ,
    & \av{\br_\mu \rho_\nu}_x &= Nr\delta_{\mu\nu} ,
    & r&=\frac{w\dg w}{N}, \\
  \sigma &= x\trans u ,
    & \av{\bs_\mu \sigma_\nu}_x &= Ns\delta_{\mu\nu} ,
    & s&=\frac{u\dg u}{N}, \\
  \tau &= x\trans v,
    & \av{\bt_\mu \tau_\nu}_x &= Nt\delta_{\mu\nu},
    & t&=\frac{v\dg v}{N}, \\
\end{aligned}
\end{equation}
%
with all other covariances negligible in the large $N$ limit.
We can now write
%
\begin{equation}\label{eq:potwuv}
\begin{aligned}
  \av{\ln Z_{\aest} (\omega,\omb)}_x =&\,  2\av{\ln\det\prn{\frac{xx\trans}{P}}}_x
  \\&
        +\av{\ln\int \prod_i\brk{ \frac{\dw_i\dwb_i}{2\pi} \frac{\du_i\dub_i}{2\pi} \frac{\dv_i\dvb_i}{2\pi} } \e^{-N(s+t)-\xi\dg A  \xi} }_{x} ,
  \\ \text{where}\quad
  \xi =&\, \begin{pmatrix}
           \rho \\
           \sigma \\
           \tau \\
         \end{pmatrix},
 \\
  A =&\, -\frac{\ir}{P}
       \begin{pmatrix}
         0        & \omb-\shift\dg & \epsilon \\
         \omega-\shift & 0            & 0 \\
         \epsilon & 0            & 0 \\
       \end{pmatrix},\\
  \av{\xi\xi\dg}_x &=  C = N\begin{pmatrix}
         r & 0 & 0 \\
         0 & s & 0 \\
         0 & 0 & t \\
       \end{pmatrix}.
\end{aligned}
\end{equation}
%
As we only care about the part of $\Phi$ that depends on $\omega$, we can ignore the first term.
We will simplify the second term using the assumption \eqref{eq:annealed}, the identity \eqref{eq:compgaussquad} and the relation
%
\begin{equation}\label{eq:spherical}
  \int \prod_i\brk{ \frac{\dw_i\dwb_i}{2\pi} } f(r) = \frac{N^N}{\Gamma(N)} \intd{r} r^{N-1} f(r),
\end{equation}
%
along with similar ones for $u$ and $v$, to get
%
\begin{equation}\label{eq:phiintsimple}
\begin{aligned}
  \Phi(\omega,\omb) &= \text{const.} + \frac{1}{4\pi N} \ln \int \frac{\dr r}{r} \frac{\dr s}{s} \frac{\dr t}{t}
      (rst)^N\e^{-N(s+t)} \av{\e^{-\xi\dg A \xi}}_x\\
      &= \text{const.} + \frac{1}{4\pi N} \ln \int \frac{\dr r}{r} \frac{\dr s}{s} \frac{\dr t}{t}
      \,\frac{\exp[N(\ln(rst)-s-t)]}{\det(I+CA)}.
\end{aligned}
\end{equation}
%
$(C\inv+A)$ IS NON-NORMAL!

As $\shift$ is unitary, all the blocks in these matrices commute.
Therefore, we can evaluate the determinant with some help from \cite{silvester2000determinants}.
Also noting that the eigenvalues of $\shift$ are $\exp(2\pi\ir k/P)$, with $k\in\Z_P$:
%
\begin{equation}\label{eq:detsimple}
\begin{aligned}
  \ln\det(I+CA) &= \ln\det\brk{\frac{1}{\alpha}
       \begin{pmatrix}
         \alpha           & -\ir r(\omb-\shift\dg) & -\ir\epsilon r \\
         -\ir s(\omega-\shift) & \alpha               & 0 \\
         -\ir\epsilon t   & 0                    & \alpha \\
       \end{pmatrix}}\\
     &= \ln\det\brk{\frac{\alpha^2+\epsilon^2rt + rs(\omb-\shift\dg)(\omega-\shift)}{\alpha^2}}\\
     &= \sum_{k=0}^{P-1} \ln\brk{ \frac{\alpha^2+\epsilon^2rt + rs (\omb-\e^{-2\pi\ir k/P}) (\omega-\e^{2\pi\ir k/P})} {\alpha^2}}\\
     &= \frac{P}{2\pi} \intd[_0^{2\pi}]{\phi} \ln\brk{ \frac{\alpha^2+\epsilon^2rt + rs (\omb-\e^{-\ir\phi}) (\omega-\e^{\ir\phi})} {\alpha^2}}\\
     &= \frac{P}{2\pi\ir} \int \frac{\dr\zeta}{\zeta} \, \ln \brk{\frac{G(\zeta)}{\alpha^2\zeta}},
\end{aligned}
\end{equation}
%
where the function $G(\zeta)$ is defined in \autoref{sec:Gamma}, in particular \eqref{eq:Gammadef}.
From \eqref{eq:zpzm}, we know that only one of the zeros of $G(\zeta)$ will lie inside the contour.
We define:
%
\begin{equation}\label{eq:zetainout}
  \brc{\zeta_>,\zeta_<} = \brc{\zeta_+,\zeta_-},
  \qquad
  \abs{\zeta_>} \geq 1,
  \qquad
  \abs{\zeta_<} \leq 1.
\end{equation}
%

If we factorise $G(\zeta)$, this contour integral is of the form discussed in \sref{sec:contourints}, the result of which appears in \eqref{eq:countourintresult}.
We find that
%
\begin{equation}\label{eq:detsimpleresult}
\begin{aligned}
  \ln\det(I+CA) &= P\ln\prn{\frac{rs\omb\zeta_>}{\alpha^2}} = P\ln\prn{\frac{rs\omega}{\alpha^2\zeta_<}}.
\end{aligned}
\end{equation}
%

Now, if we use the saddle-point approximation of the integrals over $r$, $s$ and $t$ in \eqref{eq:phiintsimple}, which becomes exact in the limit of large $N$ and $P$, we find
%
\begin{equation}\label{eq:phisaddlesimple}
  \Phi(\omega,\omb) = \frac{1}{4\pi} \max_{r,s,t} \brk{ \ln(rst) - s - t -\alpha\ln\prn{\frac{rs\omega}{\alpha^2\zeta_<}}}.
\end{equation}
%
One can show that (see \autoref{sec:replicader}, in particular \eqref{eq:repsaddlesol} and \eqref{eq:rOe}) the maximum has
%
\begin{equation}\label{eq:saddleOe}
  r \sim \CO(\epsilon\inv),
  \qquad
  s \sim \CO(\epsilon),
  \qquad
  t \sim \CO(1),
  \qquad
  rs \sim \CO(1).
\end{equation}
%
If we take $\epsilon\to0$, we find that $\Phi$ depends on $r$, $s$ and $t$ in the combinations $rs$ and $t$:
%
\begin{equation}\label{eq:phimaxsimple}
\begin{aligned}
  \Phi(\omega,\omb) &= \frac{1}{4\pi} \max_{rs,t} \brk{ (1-\alpha)\ln(rs)+\ln t - t -\alpha\ln\prn{\frac{\omega}{\alpha^2\zeta_<}}}\\
  \pdiff{\Phi}{(rs)} &= \frac{1-\alpha}{rs} + \frac{\alpha^3}{rs G'(\zeta_<)} ,\\
  \pdiff{\Phi}{t}&= \frac{1}{t} - 1 .
\end{aligned}
\end{equation}
%
Setting these derivatives to zero gives
%
\begin{equation}\label{eq:saddlecond}
  t=1,
  \qquad
  G'(\zeta_\pm)=\frac{\alpha^3}{\alpha-1},
\end{equation}
%
which can be solved for $rs$ provided that
%
\begin{equation}\label{eq:saddlereq}
  \abs{\zeta_-}\leq1,
\end{equation}
%
in which case
%
\begin{equation}\label{eq:saddlesolrs}
\begin{aligned}
  rs &= \frac{\alpha^2 \brk{ -(\alpha-1)\opo \pm \sqrt{ (\alpha-1)^2\opo^2 + (2\alpha-1)\omo^2 } }}{(\alpha-1)\omo^2},\\
\end{aligned}
\end{equation}
%
Using \eqref{eq:zppzm} and \eqref{eq:Gprime}
%
\begin{equation}\label{eq:saddlesolzm}
\begin{aligned}
  \zeta_- &= \frac{1+\abs{\omega}^2}{2\omb} - \frac{\alpha^2}{2(\alpha-1)\omb rs},\\
\end{aligned}
\end{equation}
%
and \eqref{eq:saddlereq} requires that we pick the positive root for $rs$.
Furthermore, with this choice, \eqref{eq:saddlereq} is satisfied everywhere.
Finally, dropping some constant pieces,
%
\begin{equation}\label{eq:saddlesol}
\begin{aligned}
 \Phi(\omega,\omb) &= \frac{1}{4\pi}\brk{ (1-\alpha)\ln(rs) -\alpha\ln\prn{\frac{\omega}{\zeta_<}} }.
\end{aligned}
\end{equation}
%
This will simplify if expressed in terms of $q=(\alpha-1)rs/\alpha^2$.




\section{Full, replica-tastic derivation}\label{sec:replicader}


The starting point for this version of the derivation will be \eqref{eq:partfnintwuv} and \eqref{eq:potwuv}:
%
\begin{equation}\label{eq:phiint}
  \begin{aligned}
    \Phi(\omega,\omb) &= \text{const.} + \frac{1}{4\pi N} \av{\ln \widetilde{Z}}_x, \\
    \widetilde{Z} &= \int \prod_i\brk{ \frac{\dw_i\dwb_i}{2\pi} \frac{\du_i\dub_i}{2\pi} \frac{\dv_i\dvb_i}{2\pi} } \e^{-F''}, \\
    F'' &=  u\dg u + v\dg v -\frac{\ir}{P}\brk{ w\dg x(\omb-\shift\dg)x\trans u + \epsilon w\dg xx\trans v + (\text{c.c.}) }.
  \end{aligned}
\end{equation}
%
We will use the replica trick, \ie we rewrite the logarithm as
%
\begin{equation}\label{eq:replicatrick}
  \ln \widetilde{Z} = \left. \pdiff{( \widetilde{Z}^n )}{n}\right\rvert_{n=0}.
\end{equation}
%
For integer $n$, we can compute $\widetilde{Z}^n$ by creating $n$ replicas of the system.
We then let $n\to0$ after averaging over $x$.
We index these replicas with $a,b=1,\ldots,n$:
%
\begin{equation}\label{eq:phirep}
    \begin{aligned}
    \Phi(\omega,\omb) &= \frac{1}{4\pi N}  \left.\pdiff{}{n}\av{
       \int \prod_{ia}\brk{ \frac{\dw_{ia}\dwb_{ia}}{2\pi} \frac{\du_{ia}\dub_{ia}}{2\pi} \frac{\dv_{ia}\dvb_{ia}}{2\pi} } \e^{-F'''}
       }_x\right\rvert_{n=0}, \\
    F''' &= \sum_a  u_a\dg u_a + v_a\dg v_a -\frac{\ir}{P}\brk{ w_a\dg x(\omb-\shift\dg)x\trans u_a + \epsilon w_a\dg xx\trans v_a + (\text{c.c.}) }.
  \end{aligned}
\end{equation}
%

Over most of the integration domain, we expect the Hermitian overlaps ($w_a\dg w_b, u_a\dg u_b,\ldots$) will be $\CO(N)$, whereas the non-Hermitian overlaps ($w_a\dg u_b, w_a\trans w_b,\ldots$) will be $\CO(\sqrt{N})$.
We define some new variables, $\rho_a,\sigma_a \text{ and } \tau_a$, which are zero mean Gaussian random vectors:
%
\begin{equation}\label{eq:reprstdef}
\begin{aligned}
  \rho_a &= x\trans w_a ,
    & \av{\bar{\rho}_{\mu a} \rho_{\nu b}}_x &= N\delta_{\mu\nu}R_{ab} ,
    & R_{ab}&=\frac{w_a\dg w_b}{N}, \\
  \sigma_a &= x\trans u_a ,
    & \av{\bar{\sigma}_{\mu a} \sigma_{\nu b}}_x &= N\delta_{\mu\nu}S_{ab} ,
    & S_{ab}&=\frac{u_a\dg u_b}{N}, \\
  \tau_a &= x\trans v_a,
    & \av{\bar{\tau}_{\mu a} \tau_{\nu b}}_x &= N\delta_{\mu\nu}T_{ab},
    & T_{ab}&=\frac{v_a\dg v_b}{N}, \\
\end{aligned}
\end{equation}
%
with all other covariances negligible in the large $N$ limit.
%
\begin{equation}\label{eq:phirepxi}
    \begin{aligned}
    \Phi(\omega,\omb) &= \frac{1}{4\pi N}  \left.\pdiff{}{n}
       \int \prod_{ia}\brk{ \frac{\dw_{ia}\dwb_{ia}}{2\pi} \frac{\du_{ia}\dub_{ia}}{2\pi} \frac{\dv_{ia}\dvb_{ia}}{2\pi} }
       \av{\e^{-N\Tr(S+T) - \xi\dg A \xi}}_x
       \right\rvert_{n=0}, \\
     &= \frac{1}{4\pi N}  \left.\pdiff{}{n}
       \int \prod_{ia}\brk{ \frac{\dw_{ia}\dwb_{ia}}{2\pi} \frac{\du_{ia}\dub_{ia}}{2\pi} \frac{\dv_{ia}\dvb_{ia}}{2\pi} }
       \e^{-NE(R,S,T)}
       \right\rvert_{n=0},
\end{aligned}
\end{equation}
%
where
%
\begin{equation}\label{eq:overlapenergy}
\begin{aligned}
  E(R,S,T) &= \Tr(S+T) + \frac{1}{N} \ln \det (I+CA),\\
  \xi &= \begin{pmatrix}
           \rho \\
           \sigma \\
           \tau \\
         \end{pmatrix},
 \\
  A &= -\frac{\ir}{P}
       \begin{pmatrix}
         0        & \omb-\shift\dg & \epsilon \\
         \omega-\shift & 0            & 0 \\
         \epsilon & 0            & 0 \\
       \end{pmatrix}\otimes I,\\
  \av{\xi\xi\dg}_x &=  C = N I\otimes
       \begin{pmatrix}
         R & 0 & 0 \\
         0 & S & 0 \\
         0 & 0 & T \\
       \end{pmatrix}.  \end{aligned}
\end{equation}
%

It will be helpful to separate the integrals over $w,u\text{ and }v$ into an integral over values of $w,u\text{ and }v$ with the same overlap and an integral over values of the overlap.
This can be done by inserting factors like the following into the integral:
%
\begin{equation}\label{eq:overlapdelta}
  \int \dr R_{ab} N^{n^2} \delta (N R_{ab} - w_a\dg w_b ) = 1.
\end{equation}
%
We define
%
\begin{equation}\label{eq:overlapentropy}
  S(R) = \frac{1}{N} \int \prod_{ia}\brk{ \frac{\dw_{ia}\dwb_{ia}}{2\pi} }
  N^{n^2} \delta (N R_{ab} - w_a\dg w_b )
   = \ln\det R + \text{const.}
\end{equation}
%
with the final expression valid in the large $N$ limit.
Then \eqref{eq:phirepxi} reduces to
%
\begin{equation}\label{eq:phioverlap}
  \Phi(\omega,\omb) = \frac{1}{4\pi N}  \left.\pdiff{}{n}
       \int \dr R_{ab} \dr S_{ab} \dr T_{ab}
       \,\e^{-N(E(R,S,T)-S(R)-S(S)-S(T))}
       \right\rvert_{n=0}.
\end{equation}
%
We will perform this integral in the large $N$ limit with the saddle point method.

We make the following, replica-symmetric ans\"atze for the saddle-point:
%
\begin{equation}\label{eq:RSansatze}
  R_{ab} = r_0\delta_{ab} + r_1,
  \qquad
  S_{ab} = s_0\delta_{ab} + s_1,
  \qquad
  T_{ab} = t_0\delta_{ab} + t_1.
\end{equation}
%
A matrix of this form has $(n-1)$ eigenvalues equal to $r_0$ and one eigenvalue equal to $(r_0+nr_1)$.
Therefore,
%
\begin{equation}\label{eq:RSentropy}
  S(R) = \ln\det R = (n-1)\ln r_0 + \ln(r_0 +n r_1) = n\ln r_0 + \frac{nr_1}{r_0} + \CO(n^2).
\end{equation}
%
The replica symmetric form of $R,S,T$ and the unitarity of $\shift$ means that all the blocks in \eqref{eq:overlapenergy} commute.
Then, according to \cite{silvester2000determinants},
%
\begin{equation}\label{eq:detrep}
\begin{aligned}
  \ln\det(I+CA) &=  \ln\det\brk{\frac{1}{\alpha}
       \begin{pmatrix}
         \alpha                   & -\ir (\omb-\shift\dg) \otimes R & -\ir\epsilon I\otimes R \\
         -\ir (\omega-\shift)\otimes S & \alpha                        & 0 \\
         -\ir\epsilon I\otimes T  & 0                             & \alpha \\
       \end{pmatrix}}\\
     &= \ln\det\brk{\frac{\alpha^2+\epsilon^2I\otimes RT + (\omb-\shift\dg)(\omega-\shift)\otimes RS}{\alpha^2}}.
\end{aligned}
\end{equation}
%
Note that
%
\begin{equation}\label{eq:overlapprod}
  (RS)_{ab} = r_0s_0 \delta_{ab} + r_0 s_1 + r_1 s_0 + \CO(n),
\end{equation}
%
and similar for $RT$, so these will have a similar eigenvalue structure to $R$, with the same eigenvectors.
Also, the eigenvalues of $\shift$ are $\exp(2\pi\ir k/P)$, with $k\in\Z_P$.
Therefore:
%
\begin{equation}\label{eq:detrepints}
\begin{aligned}
  \ln\det(I+CA) &=  \sum_{k=0}^{P-1}
    n \left\{
      \ln\brk{ \frac{\alpha^2+\epsilon^2r_0t_0 + r_0s_0 (\omb-\e^{-2\pi\ir k/P}) (\omega-\e^{2\pi\ir k/P})} {\alpha^2}}
    \right.\\
    &\qquad\quad \left.+
      \frac{ \epsilon^2 (r_0t_1+r_1t_0) + (r_0s_1+r_1s_0) (\omb-\e^{-2\pi\ir k/P}) (\omega-\e^{2\pi\ir k/P})} { \alpha^2+\epsilon^2r_0t_0 + r_0s_0 (\omb-\e^{-2\pi\ir k/P}) (\omega-\e^{2\pi\ir k/P})}
    \right\}\\
   &\qquad +\CO(n^2)\\
    &= \frac{nP}{2\pi} \intd[_0^{2\pi}]{\phi} \left\{
     \ln\brk{ \frac{\alpha^2+\epsilon^2r_0t_0 + r_0s_0 (\omb-\e^{-\ir\phi}) (\omega-\e^{\ir\phi})} {\alpha^2}}
    \right.\\
    &\qquad\quad \left.+
      \frac{ \epsilon^2 (r_0t_1+r_1t_0) + (r_0s_1+r_1s_0) (\omb-\e^{-\ir\phi}) (\omega-\e^{\ir\phi})} { \alpha^2+\epsilon^2r_0t_0 + r_0s_0 (\omb-\e^{-\ir\phi}) (\omega-\e^{\ir\phi})}
    \right\}\\
    &= \frac{nP}{2\pi\ir} \int \frac{\dr\zeta}{\zeta} \left\{ \ln \brk{\frac{G(\zeta)}{\alpha^2\zeta}}
    \right.\\
    &\qquad\quad \left.+
      \frac{ \epsilon^2 (r_0t_1+r_1t_0)\zeta + (r_0s_1+r_1s_0) (\omb\zeta-1) (\omega-\zeta)} {G(\zeta)}
    \right\},
\end{aligned}
\end{equation}
%
where the function $G(\zeta)$ is defined in \autoref{sec:Gamma}, in particular \eqref{eq:Gammadef}.
The first integral was computed in \eqref{eq:detsimpleresult}.
The second can be computed with the residue theorem.
The integrand has poles at $\zeta\in\brc{0,\zeta_+,\zeta_-}$, with only one of the last two lying inside the contour (see \eqref{eq:zppzm}).
Using the definitions \eqref{eq:zetainout},
%
\begin{multline}\label{eq:repcontoutint}
  \int \frac{\dr\zeta}{2\pi\ir\,\zeta}\,
    \frac{ \epsilon^2 (r_0t_1+r_1t_0)\zeta + (r_0s_1+r_1s_0) (\omb\zeta-1) (\omega-\zeta)} {G(\zeta)} \\
    \begin{aligned}
      &= \frac{(r_0s_1+r_1s_0)(-\omega)}{G(0)}
      + \frac{ \epsilon^2 (r_0t_1+r_1t_0)\zeta_< + (r_0s_1+r_1s_0) (\omb\zeta_<-1) (\omega-\zeta_<)} {\zeta_< G'(\zeta_<)} \\
      &= \frac{r_0s_1+r_1s_0}{r_0s_0}\prn{1-\frac{\alpha^2+\epsilon^2r_0t_0} {G'(\zeta_<)}}
      + \frac{ \epsilon^2 (r_0t_1+r_1t_0)} {G'(\zeta_<)} .
    \end{aligned}
\end{multline}
%

Combining all of this gives:
%
\begin{equation}\label{eq:phimaxrep}
\begin{aligned}
  \Phi(\omega,\omb) =\, \frac{1}{4\pi} \max_{r_{0,1},s_{0,1},t_{0,1}}& \left\{
    \ln(r_0s_0t_0) + \frac{r_1}{r_0} + \frac{s_1}{s_0} + \frac{t_1}{t_0}
    -(s_0 + s_1 + t_0 + t_1)
    \right.\\&\left.
    - \alpha\ln\prn{\frac{r_0s_0\omega}{\alpha^2\zeta_<}}
    - \frac{\alpha(r_0s_1+r_1s_0)}{r_0s_0}\prn{1-\frac{\alpha^2+\epsilon^2r_0t_0} {G'(\zeta_<)}}
    \right.\\&\left.
    - \frac{ \alpha\epsilon^2 (r_0t_1+r_1t_0)} {G'(\zeta_<)}
    \right\}.
\end{aligned}
\end{equation}
%
To find the maximum, we must set the following derivatives to zero
%
\begin{equation}\label{eq:phidiff1}
\begin{aligned}
  \pdiff{(4\pi\Phi)}{r_1} &= \frac{1}{r_0} - \frac{\alpha}{r_0} + \frac{\alpha^3}{r_0G'(\zeta_<)},  \\
  \pdiff{(4\pi\Phi)}{s_1} &= \frac{1}{s_0} - 1 - \frac{\alpha}{s_0} + \frac{\alpha(\alpha^2+\epsilon^2 r_0 t_0 )}{s_0G'(\zeta_<)},  \\
  \pdiff{(4\pi\Phi)}{t_1} &= \frac{1}{t_0} - 1 - \frac{\alpha\epsilon^2r_0}{G'(\zeta_<)},
\end{aligned}
\end{equation}
%
as well as
%
\begin{equation}\label{eq:phidiff0}
\begin{aligned}
  \pdiff{(4\pi\Phi)}{r_0} &= \pdiff{(4\pi\Phi)}{r_1} +(\cdots)r_1+(\cdots)s_1+(\cdots)t_1,  \\
  \pdiff{(4\pi\Phi)}{s_0} &= \pdiff{(4\pi\Phi)}{s_1} +(\cdots)r_1+(\cdots)s_1+(\cdots)t_1,  \\
  \pdiff{(4\pi\Phi)}{t_0} &= \pdiff{(4\pi\Phi)}{t_1} +(\cdots)r_1+(\cdots)s_1+(\cdots)t_1.
\end{aligned}
\end{equation}
%
This has the solution $r_1=s_1=t_1=0$,
which justifies the annealed assumption in \eqref{eq:annealed}.
Solving \eqref{eq:phidiff1} gives
%
\begin{equation}\label{eq:repsaddlesol}
  G'(\zeta_<) = \frac{\alpha^3}{\alpha-1},
  \qquad
  s_0 = \frac{(\alpha-1)\epsilon^2r_0}{\alpha^2+(\alpha-1)\epsilon^2r_0},
  \qquad
  t_0 = 1 - s_0.
\end{equation}
%
Expression \eqref{eq:Gprimesol} for $G'(\zeta_\pm)$ tells us that it must be $\zeta_-$ that lies inside the unit circle.
Solving for $r_0$ is a mess, but we can see that no solutions exist for $r_0<\CO(\epsilon\inv)$ or $r_0>\CO(\epsilon\inv)$ as $\epsilon\to0$, because the last equation would reduce to
\begin{equation}\label{eq:rOe}
\begin{aligned}
  r_0 &\sim \CO(\epsilon^{-1+\delta})
   \implies &
   \alpha^2 &= \frac{\alpha^3}{\alpha-1}, \\
  r_0 &\sim \CO(\epsilon^{-1-\delta})
   \implies &
   \frac{(\alpha-1)\omo^2\epsilon^2r_0^2}{\alpha^2+(\alpha-1)\epsilon^2r_0} &= \frac{\alpha^3}{\alpha-1}. \\
\end{aligned}
\end{equation}
%
Combined with \eqref{eq:repsaddlesol}, this justifies \eqref{eq:saddleOe}.


\section{Relation to canonical angles}\label{sec:canonang}

What would happen if we replaced the shift matrix, $\shift$, with some other unitary matrix?
Looking at \eqref{eq:detsimple} or \eqref{eq:detrepints}, we see that it is only the eigenvalue density of $\shift$ that matters.
Therefore, any unitary matrix with eigenvalue uniformly distributed around the unit circle would lead the the same eigenvalue distribution for $\aest$.
Furthermore, following the argument from \eqref{eq:detsimple} to \eqref{eq:phisaddlesimple}, or from \eqref{eq:detrepints} to \eqref{eq:phimaxrep}, we see that the eigenvalue distribution of $\aest$ depends linearly on the eigenvalue density of $\shift$.
Therefore, if $\shift$ were chosen randomly we would just use the mean eigenvalue distribution of a random unitary matrix.
As this is uniformly distributed around the unit circle, this would also lead the the same eigenvalue distribution for $\aest$.

Now, let us introduce the singular-value-decomposition of $x$:
%
\begin{equation}\label{eq:svd}
  x = UDV\trans,
\end{equation}
%
where $U$ is an $N\times N$ orthogonal matrix, $D$ is an $N\times N$ diagonal matrix and $V$ is an $N\times P$ row-orthogonal matrix:
%
\begin{equation}\label{eq:svdorth}
  UU\trans = U\trans U = VV\trans = \I.
\end{equation}
%
We can write \eqref{eq:Aest} as
%
\begin{equation}\label{eq:Aestsvd}
\begin{aligned}
  \aest &= UDV\trans\shift VDU\trans (UDV\trans VDU\trans)\inv \\
   &= UDV\trans\shift VDU\trans UD^{-2}U\trans \\
   &= UDV\trans\shift VD\inv U\trans \\
   &= (UD)(V\trans\shift V)(UD)\inv.
\end{aligned}
\end{equation}
%
Thus, $\aest$ is similar to $V\trans\shift V$, and therefore has the same eigenvalues.
Now, $V$ is a random $N\times P$ row-orthogonal matrix.
If $\shift$ is chosen randomly, $V'=\shift V$ is another random $N\times P$ row-orthogonal matrix, independent of $V$.

We can think of $V$ and $V'$ as basis vectors for $N$-dimensional subspaces of a $P$-dimensional space and $V\trans\shift V=V\trans V'$ as the matrix of inner-products of these vectors.
The singular values of this matrix are known as the canonical angles.
They are used in high-dimensional data-analysis and the case of two random, independent subspaces is an important null-model.

In our case, however, we are interested in the eigenvalues, not the singular values.

%\subsection*{Acknowledgements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\startappendices
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Complex Gaussian integrals}\label{sec:compgauss}

First, Let's get all of the factors of 2 straight.
Note that if we write $z=x+\ir y$, then $\dz\dzb = 2\dx\dy$.
Let $H$ be a positive-definite, $N\times N$ Hermitian matrix
(or just a normal matrix whose eigenvalues have positive real parts).
Consider an integral  of the form
%
\begin{equation*}
  \int \prn{\prod_i\dz_i\dzb_i} \exp\prn{-z\dg H z}.
\end{equation*}
%
We can diagonalise $H$ with a unitary change of variables:
%
\begin{equation}\label{eq:compgausint}
\begin{aligned}
  \int \prn{\prod_i\dz_i\dzb_i} \exp\prn{-z\dg H z} &=
    \prod_i \int \dz_i\dzb_i\, \exp\prn{-\lambda_i \abs{z_i}^2} \\
    &= \prod_i \int \dx_i\dy_i\, 2\exp\prn{-\lambda_i \prn{x_i^2+y_i^2}} \\
    &= \prod_i \frac{2\pi}{\lambda_i}\\
    &= \frac{(2\pi)^N}{\det H}.
\end{aligned}
\end{equation}
%

The proper normalisation for a Gaussian distribution is
%
\begin{equation}\label{eq:compgaussnorm}
  P(z,z\dg)\dz\dz\dg = \prn{\prod_i\frac{\dz_i\dzb_i}{2\pi}} \frac{\exp\prn{-z\dg C\inv z}}{\det C}.
\end{equation}
%
By completing the square, we can see that
%
\begin{equation}\label{eq:compgausslin}
  \av{\exp\prn{\zeta\dg z \pm z\dg\zeta}} = \exp\prn{\pm\zeta\dg C\zeta}
\end{equation}
%
Taking partial derivatives \wrt $\zeta_i$ and $\bar{\zeta}_i$, we find
%
\begin{equation}\label{eq:compgauscov}
  \av{zz\dg} = C.
\end{equation}
%

Now consider an integral of the form
%
\begin{equation}\label{eq:compgaussquad}
\begin{aligned}
  \av{\exp\prn{-z\dg A z}} &=
    \int \prn{\prod_i\frac{\dz_i\dzb_i}{2\pi}}\frac{\exp\prn{-z\dg (C\inv+A) z}}{\det C} \\
    &= \prn{\det C\det\prn{C\inv+A}}\inv \\
    &= \det\prn{I+CA}\inv.
\end{aligned}
\end{equation}
%
ONLY WORKS IF $(C\inv+A)$ IS POS DEF, OR AT LEAST NORMAL!

Does it matter if the matrix is normal?
Suppose we diagonalise with a non-unitary transformation.
What Jacobian factor would we pick up?
%
\begin{equation*}
\begin{aligned}
  \begin{aligned}
    z'   &= Sz, \\
    \zb' &=S\inv\zb,
  \end{aligned}
  &\implies
  \begin{aligned}
    x' &= \frac{z'+\zb'}{2}    = \frac{S+S\inv}{2}x - \frac{S-S\inv}{2\ir}y, \\
    y' &= \frac{z'-\zb'}{2\ir} = \frac{S-S\inv}{2\ir}x - \frac{S+S\inv}{2}y,
  \end{aligned}
  \\ &
  \begin{aligned}
  \implies  \det J &= \det\begin{pmatrix}
                    \frac{S+S\inv}{2}    & -\frac{S-S\inv}{2\ir} \\
                    \frac{S-S\inv}{2\ir} & \frac{S+S\inv}{2} \\
                  \end{pmatrix}
     \\
     &= \det \brk{\prn{\frac{S+S\inv}{2}}^2-\prn{\frac{S-S\inv}{2\ir}}^2}\\
     &=\det S S\inv = 1.
  \end{aligned}
\end{aligned}
\end{equation*}
%
The change in contours can be undone, as the integrand is analytic in $x$ and $y$.


\section{Contour integrals for determinants}\label{sec:contourints}

In evaluating determinants in \autoref{sec:simplederiv}, we will come across contour integrals of the form
%
\begin{equation}\label{eq:contourint}
  I(\zeta_\gtrless) = \oint_C \frac{\dr\zeta}{2\pi\ir\,\zeta} \, \ln\prn{\frac{\gamma(\zeta_>-\zeta)(\zeta-\zeta_<)}{\zeta}},
\end{equation}
%
where the contour is the unit circle in a counter-clockwise direction and $\abs{\zeta_\gtrless}\gtrless1$.
We choose the branch of the logarithm so that
%
\begin{equation}\label{eq:branch}
  \arg\prn{\frac{\zeta-\zeta_<}{\zeta_<}},\arg\prn{\frac{\zeta}{\zeta_<}} \in [0,2\pi],
\end{equation}
%
and we define $\theta=\arg z$.
The branch cut at $\zeta=\zeta_>$ will not matter.
The branch cuts and contour are shown in \autoref{fig:contours}(\ref{fig:branches}).

\begin{figure}
 \begin{center}
 \begin{myenuma}
  \item\aligntop{\includegraphics[width=4cm]{branches.svg}}\label{fig:branches}
  \hspace{0.5cm}
  \item\aligntop{\includegraphics[width=4cm]{contout.svg}}\label{fig:contout}
  \hspace{0.5cm}
  \item\aligntop{\includegraphics[width=4cm]{contin.svg}}\label{fig:contin}
 \end{myenuma}
 \end{center}
  \caption{(\ref{fig:branches}) Contours used to evaluate \eqref{eq:contourint} and and branch cuts \eqref{eq:branch}.
  (\ref{fig:contout}) contour used with singularities at $\zeta_>$.
  (\ref{fig:contin}) contour used with singularities at $\zeta_<,0$.
  Branch cuts indicated by dashed line.
  Poles and branch points indicated by crosses.}\label{fig:contours}
\end{figure}

We write
%
\begin{equation}\label{eq:contoursplit}
  I(\zeta_\gtrless) = \oint_C \frac{\dr\zeta}{2\pi\ir\,\zeta}\, \ln\gamma(\zeta_>-\zeta) + \oint_C \frac{\dr\zeta}{2\pi\ir\,\zeta}\, \ln\prn{\frac{\zeta-\zeta_<}{\zeta}},
\end{equation}
%

For the first part, we can use the original contour $C$ as in \autoref{fig:contours}(\ref{fig:contout}).
Using the residue theorem:
%
\begin{equation}\label{eq:intout}
  \int \frac{\dr\zeta}{2\pi\ir\,\zeta}\, \ln\gamma(\zeta_>-\zeta) = \ln \gamma\zeta_>.
\end{equation}
%

For the second part, we can deform the contour to $C'$ as in \autoref{fig:contours}(\ref{fig:contin}):
%
\begin{equation}\label{eq:contout}
C': \quad
  \begin{aligned}
    \zeta &= \epsilon\e^{\ir\phi},                         & \phi &\in [\theta,\theta+2\pi], \\
    \zeta &= x \e^{\ir(\theta+2\pi)},                      & x    &\in [\epsilon,\abs{\zeta_<}-\epsilon], \\
    \zeta &= \zeta_< + \epsilon\e^{\ir\phi},               & \phi &\in [\theta-\pi,\theta+\pi], \\
    \zeta &= (\abs{\zeta_<}-x) \e^{\ir\theta},\quad & x    &\in [\epsilon,\abs{\zeta_<}-\epsilon]. \\
  \end{aligned}
\end{equation}
%
The integral over the third part vanishes as $\epsilon\to0$.
The second and fourth parts would cancel, if not for the discontinuity in the logarithm of the denominator
(the logarithm of the numerator has no discontinuity, due to \eqref{eq:branch}).
This leaves:
%
\begin{equation}\label{eq:intin}
\begin{aligned}
  \oint_{C'} \frac{\dr\zeta}{2\pi\ir\,\zeta}\, \ln\prn{\frac{\zeta-\zeta_<}{\zeta}}
    &= \int_{\theta}^{\theta+2\pi}\frac{\dr\phi}{2\pi} \ln\prn{\frac{\epsilon\e^{\ir\phi}-\zeta_<}{\epsilon\e^{\ir\phi}}}
     + \int_{\epsilon}^{\abs{\zeta_<}-\epsilon} \frac{\dx}{2\pi\ir\,x} \operatorname{disc}\ln\prn{\frac{1}{\zeta}}\\
    &= \ln\prn{\frac{\e^{\ir\pi}\zeta_<}{\epsilon}}
     -  \int_{\theta}^{\theta+2\pi} \frac{\ir\phi\,\dr\phi}{2\pi}
     - \int_{\epsilon}^{\abs{\zeta_<}} \frac{\dx}{x}\\
    &= \ln\prn{\frac{\zeta_<}{\epsilon}} +\ir\pi
     - \ir(\theta+\pi)
     - \ln\prn{\frac{\abs{\zeta_<}}{\epsilon}}\\
    &= 0.
\end{aligned}
\end{equation}
%

Therefore:
%
\begin{equation}\label{eq:countourintresult}
  I(\zeta_\gtrless) = \ln\gamma\zeta_>.
\end{equation}
%


\section{The quadratic function \texorpdfstring{$G(\zeta)$}{G(zeta)}}\label{sec:Gamma}

In evaluating determinants in \autoref{sec:simplederiv} and \autoref{sec:replicader}, we come across the function
%
\begin{equation}\label{eq:Gammadef}
  G(\zeta) = (\alpha^2+\epsilon^2rt)\zeta + rs(\omb\zeta-1)(\omega-\zeta) = - rs\omb (\zeta-\zeta_+) (\zeta-\zeta_-).
\end{equation}
%
We will collect some useful features of $\zeta_\pm$ here.

First, by comparing the two forms of $G(\zeta)$, we see that:
%
\begin{align}
\label{eq:zpzm}
  \zeta_+ \zeta_- &= \frac{\omega}{\omb},\\
  \label{eq:zppzm}
  \zeta_+ + \zeta_- &= \frac{\alpha^2+\epsilon^2rt + rs\opo}{rs\omb},\\
  \label{eq:Gprime}
  G'(\zeta_\pm) &= \mp rs\omb(\zeta_+ - \zeta_-),
\end{align}
%
and \eqref{eq:zpzm} tells us that $\abs{\zeta_+} \abs{\zeta_-}=1$.
Solving the equation $G(\zeta_\pm)=0$ gives
%
\begin{align}
\label{eq:zetapm}
  \zeta_\pm &= \frac{ \alpha^2+\epsilon^2rt + rs(1+\abs{\omega})^2
     \pm \sqrt{\brk{\alpha^2+\epsilon^2rt + rs(1+\abs{\omega})^2}
       - 4(rs)^2\abs{\omega}^2} }{2rs\omb},\\
%\label{eq:zpmzm}
%  \zeta_+ - \zeta_- &= \frac{\sqrt{\brk{\alpha^2+\epsilon^2rt + rs\opo}
%       - 4(rs)^2\abs{\omega}^2} }{rs\omb},\\
\label{eq:Gprimesol}
  G'(\zeta_\pm) &= \mp\sqrt{\brk{\alpha^2+\epsilon^2rt + rs\opo}^2
       - 4(rs)^2\abs{\omega}^2}.
\end{align}
%
Differentiating the equation $G(\zeta_\pm)=0$ gives
%
\begin{equation}\label{eq:dzpmdrst}
\begin{aligned}
%\label{eq:dzpmdr}
  \pdiff{\zeta_\pm}{r} &=
    -\frac{\epsilon^2t\zeta_\pm + s(\omb\zeta_\pm-1)(\omega-\zeta_\pm)}{G'(\zeta_\pm)}
    &&= \frac{\alpha^2\zeta_\pm}{rG'(\zeta_\pm)},\\
%\label{eq:dzpmds}
  \pdiff{\zeta_\pm}{s} &=
    -\frac{r(\omb\zeta_\pm-1)(\omega-\zeta_\pm)}{G'(\zeta_\pm)}
    &&= \frac{(\alpha^2+\epsilon^2rt)\zeta_\pm}{sG'(\zeta_\pm)},\\
%\label{eq:dzpmdt}
  \pdiff{\zeta_\pm}{r} &=
    -\frac{\epsilon^2r\zeta_\pm}{G'(\zeta_\pm)}.
\end{aligned}
\end{equation}
%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{utcaps_sl}
\bibliography{maths,neuro}

\end{document}
